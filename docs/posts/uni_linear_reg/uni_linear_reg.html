
<!DOCTYPE html>
<html>

  <head>
  <link rel="apple-touch-icon" sizes="180x180" href="../../images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="../../images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../images/favicon-16x16.png">
  <link rel="manifest" href="../../images/site.webmanifest">
  <link rel="mask-icon" href="../../images/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="shortcut icon" href="../../images/favicon.ico">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-config" content="/assets/logos/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
    

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-141821189-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-141821189-1');
</script>

  
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Univariety Linear Regression</title>
  <meta name="description" content="Cross-posted from Microsoft Research Blog">

  
  
  <link rel="stylesheet" href="https://decentdescent.org/assets/style.css">

  <link rel="canonical" href="https://decentdescent.org/tp5.html">
  <link rel="alternate" type="application/rss+xml" title="Decent Descent" href="https://decentdescent.org/feed.xml">

  <script async defer src="https://buttons.github.io/buttons.js"></script>


  <!-- mathjax -->
  <!-- <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script> -->
  <!-- <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	jax: ["input/TeX","output/HTML-CSS"],
	displayAlign: "left",
	displayIndent: "2em"
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script> -->
  <!-- mathjax v3 -->
<!--
  <script type="text/javascript">
  document.addEventListener('DOMContentLoaded', function(){
    function stripcdata(x) {
      if (x.startsWith('% <![CDATA[') && x.endsWith('%]]>'))
	return x.substring(11,x.length-4);
      return x;
    }
    document.querySelectorAll("script[type='math/tex']").forEach(function(el){
      el.outerHTML = "\\(" + stripcdata(el.textContent) + "\\)";
    });
    document.querySelectorAll("script[type='math/tex; mode=display']").forEach(function(el){
      el.outerHTML = "\\[" + stripcdata(el.textContent) + "\\]";
    });
    var script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js";
    document.head.appendChild(script);
  }, false);
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
-->
  <!-- Load jQuery -->
  <!--
  <script src="//code.jquery.com/jquery-1.11.1.min.js"></script>
  -->
  <!-- Load KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <!--
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
  -->

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <!--
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
  -->
</head>


  <body>

    <header class="px-2 clearfix">
  <div class="left sm-width-full py-1 mt-1 mt-lg-0">
    <!--
    <a class="align-middle link-primary text-accent" href="/">
      Decent Descent
    </a>
    -->
    <a class="align-middle link-primary mt-1" href="/">
        <img src="../../images/decent_descent_abbrev_black_text2path.svg" height="36" width="auto">
    </a>
  </div>
  <div class="right sm-width-full">
    <ul class="list-reset mt-lg-1 mb-2 mb-lg-1">
      
        
      
        
        <li class="inline-block">
          <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="../../about.html">
            About
          </a>
        </li>
        
      
        
      
        
      
        
      
    </ul>
  </div>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.css" integrity="sha384-dbVIfZGuN1Yq7/1Ocstc1lUEm+AT+/rCkibIcC/OmWo5f0EA48Vf8CytHzGrSwbQ" crossorigin="anonymous">
</header>


    <div>
      

<article class="container px-2 mx-auto mb4" itemscope itemtype="http://schema.org/BlogPosting">
  
  <h1 class="h0 col-9 sm-width-full py-0 mt-7 mb-0 inline-block" itemprop="name headline">Univariety Linear Regression</h1>
  <h1 class="h1 col-9 sm-width-full py-0 mt-0 mb-4 inline-block" itemprop="name headline">C Programming</h1>
  
  <div class="col-12 sm-width-full mt-1 border-top-thin ">
    <p class="text-accent mb-0 pt-2 pb-0 bold authordate"><a class='link-authordate' href="https://x.com/oderoi">Isack Odero</a> 
    </p>
    <p class="mb-1 pt-0 pb-0 bold authordate"><time datetime="2022-03-08T14:00:00+00:00" itemprop="datePublished">July 8, 2024</time>
    
  <div class="table">
    <div class="inline-block mb-0 mr-1">
      <a href="https://arxiv.org/abs/2203.03466" title="Read the Paper" class="link-social block">
  <svg height="32" class="header-social-op" version="1.1" width="32" viewBox="0 0 16 16" aria-hidden="true" fill-rule="evenodd">
    <path d="M8,0C3.6,0,0,3.6,0,8s3.6,8,8,8s8-3.6,8-8S12.4,0,8,0z 
             M9.08 2.6H4.76c-.595 0-1.08.485-1.08 1.08v8.64c0 .595.485 1.08 1.08 1.08h6.48c.595 0 1.08-.485 1.08-1.08V5.84zm2.43 3.78H8.54V3.41z"/>
  </svg>
</a>

    </div>
    <div class="inline-block mb-0">
      <a href="https://github.com/oderoi" title="Clone the Code" class="link-social block">
<svg height="32" class="octicon octicon-mark-github header-social-op" viewBox="0 0 16 16" version="1.1" width="32" aria-hidden="true"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
</svg>
</a>

    </div>
  </div>
    
    </p>
  </div>

  <div class="prose" itemprop="articleBody">
      <!-- <p><em>Cross-posted from <a href="https://www.microsoft.com/en-us/research/blog/%c2%b5transfer-a-technique-for-hyperparameter-tuning-of-enormous-neural-networks/">Microsoft Research Blog</a></em></p> -->

<!-- ![An animated line-plot showing the stability of optimal learning rate as we change the neural network's parametrization. The parametrization is varied by interpolating between mup-Parametrization and PyTorch default in terms of the scaling for the learning rate and the initialization scale. The animation shows that mu-Parametrization is the only parametrization that preserves the optimality of learning rate across model widths; it also achieves the best absolute performance across all parametrizations.](https://www.microsoft.com/en-us/research/uploads/prod/2022/03/1400x788_Hyperparameters_no_logo_hero.gif) -->

<!-- <p><img src="/assets/tp5/anim_notitle_verbose.gif" class="limit-height" style="max-height:300px;" /></p> -->

<h3>1.0 Problem statement</h3>

<p>Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet.</p>

<ul>
  <li>You would like to expand your business to cities that may give your restaurant higher profits.</li>
  <li>The chain already has restaurants in various cities and you have data for profits and populations from the cities.</li>
  <li>You also have data on cities that are candidates for a new restaurant.</li>
  <ul>
    <li>For these cities, you have the city population.</li>
  </ul>
</ul>
<p>Can you use the data to help you identify which cities may potentially give your business higher profits?</p>

<ul>
  <li>Note:</li>
  <ul>
    <li>X is the population of a city</li>
    <li>y is the profit of a restaurant in that city. A negative value for profit indicates a loss.</li>
    <ul>
      <li>Both X and y are arrays.</li>
    </ul>
  </ul>
</ul>

<table>
  <tr>
    <th>Population of a city (\(x\) 10,000) as \(x\)$ </th>
    <th>Profit of a restaurent (\(x\) $10,000) as \( f_{w,b}(x^{(i)}) \)or \(x\)$ </th>
    
</tr>
  <tr>
    <td>6.1101</td>
    <td>17.592</td>
  </tr>
  <tr>
    <td>5.5277</td>
    <td>9.1302</td>
  </tr>
  <tr>
    <td>8.5186</td>
    <td>13.662</td>
  </tr>
  <tr>
    <td>7.0032</td>
    <td>11.854</td>
  </tr>
  <tr>
    <td>5.8598</td>
    <td>6.8233</td>
  </tr>
</table>
<p>Number of training example (size (1000 sqft) as x) \(m\)</p>
<p>In this case \(m = 5\)</p>
<!-- [Read the paper](https://www.microsoft.com/en-us/research/publication/tuning-large-neural-networks-via-zero-shot-hyperparameter-transfer/)

[Download the code](http://github.com/microsoft/mup) -->

<h3>2.0 Model Function</h3>
<p>The model function for linear regression (which is a function that maps from \(x\) to \(y\) is represented as</p>
<p>$$f_{w,b}(x^{(i)}) = w*x^{(i)} + b \tag{1}$$</p>
<!-- [![Two line-plots showing the change in activation scale between PyTorch default and the µ-Parametrization. Under PyTorch default, the activation scale grows as the network width increases for a particular time step. Under µ-Parametrization, the activation scale is stable across widths for a particular time step. ](https://www.microsoft.com/en-us/research/uploads/prod/2022/03/logits_attnlogits_embedding_edited.jpg)](https://www.microsoft.com/en-us/research/uploads/prod/2022/03/logits_attnlogits_embedding_edited.jpg) -->


<h3>3.0 Compute Cost</h3>
<p>Cost is the measure of how well our model will predict the target output well, in this case target output is Profit of a restaurent.</p>
<p>Gradient descent involve repeated steps to adjust the values of <b>w</b> and <b>b</b> to get smaller and smaller <b>Cost</b>, \(J(w,b)\).</p>
<p>The equation for Cost with one variable</p> 
$$J(w,b) = \frac{1}{2m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \tag{2}$$ 

<p>where</p> 
  $$f_{w,b}(x^{(i)}) = w*x^{(i)} + b \tag{1}$$
  
<ul>
  <li>\(f_{w,b}(x^{(i)}) \)is our prediction for example $i$ using parameters \(w,b\).</li>
  <li>\((f_{w,b}(x^{(i)}) -y^{(i)})^2\) is the squared difference between the target value and the prediction. </li>
  <li>These differences are summed over all the $m$ examples and divided by <b>2*m</b> to produce the cost, \(J(w,b)\).</li>
</ul>
   
<p>Note,</p> 
<ul>
  <li>
    Summation ranges are typically from 1 to m, while code will be from 0 to m-1.
  </li>
</ul>


<h4>3.1 Cost versus iterations of gradient descent</h4>

<p>A plot of cost versus iterations is a useful measure of progress in gradient descent. Cost should always decrease in successful runs. The change in cost is so rapid initially, it is useful to plot the initial decent on a different scale than the final descent. In the plots below, note the scale of cost on the axes and the iteration step.</p>

<img src="../../images/cost.png" height="100" width="auto">


<h4>3.2 Plot of cost J(w,b) vs w,b with path of gradient descent</h4>

<p>Plot shows the $cost(w,b)$ over a range of $w$ and $b$. Cost levels are represented by the rings. Overlayed, using red arrows, is the path of gradient descent. Here are some things to note:</p>
<ul>
  <li>The path makes steady (monotonic) progress toward its goal.</li>
  <li>initial steps are much larger than the steps near the goal.</li>
</ul>

<img src="../../images/counter_cost.png" height="100", width="auto">

<h4>3.3 Convex Cost surface</h4>

<p>The fact that the cost function squares the loss, \( \sum_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2\)  ensures that the 'error surface' is convex like a soup bowl. It will always have a minimum that can be reached by following the gradient in all dimensions.</p>

<h3>4.0 Gradient Descent</h3>
<p>In linear regression, we utilize input training data to fit the parameters \(w\),\(b\) by minimizing a measure of the error between our predictions \(f_{w,b}(x^{(i)})\) and the actual data \(y^{(i)}\). The measure is called the $cost$, \(J(w,b)\). In training you measure the cost over all of our training samples \(x^{(i)},y^{(i)}\)</p>
$$\begin{align*} \text{repeat}&\text{ until convergence:} \; \lbrace \newline
\;  w &= w -  \alpha \frac{\partial J(w,b)}{\partial w} \tag{3}  \; \newline 
 b &= b -  \alpha \frac{\partial J(w,b)}{\partial b}  \newline \rbrace
\end{align*}$$
where, parameters \(w\), \(b\) are updated simultaneously.  
The gradient is defined as:
$$
\begin{align}
\frac{\partial J(w,b)}{\partial w}  &= \frac{1}{m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})*x^{(i)} \tag{4}\\
  \frac{\partial J(w,b)}{\partial b}  &= \frac{1}{m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \tag{5}\\
\end{align}
$$

<p>Here *simultaniously* means that you calculate the partial derivatives for all the parameters before updating any of the parameters.</p>

<h3>4.1 Cost vs w, with gradients, b set to 100.</h3>

<p>The plot shows \(\frac{\partial J(w,b)}{\partial w}\) or the slope of the cost curve relative to $w$ at three points. The derivative is negative. Due to the 'bowl shape', the derivatives will always lead gradient descent toward the bottom where the gradient is zero.</p>

![gradient](images/grads.png)
<img src="../../images/grads.png" height="100", width="auto">

 <h3>5.0 Evaluating our model</h3>

<p>To evaluate the estimation model, we use coefficient of determination which is given by the following formula:</p>
$$
R^2 = 1 - \frac{Residual\ Square\ Sum}{Total\ Square\ Sum}
$$


$$
R^2 = 1 - \frac{\sum\limits_{i=0}^{(m-1)}(f_{w,b}(x^{(i)}) - y^{i})^2}{\sum\limits_{i=0}^{(m-1)}(f_{w,b}(x^{(i)}) - f_{w,b}(x^{(i)})_{mean})^2}
$$

<h3>6.0 Learning parameters using batch gradient descent </h3>

<p>You will now find the optimal parameters of a linear regression model by using batch gradient descent. Recall batch refers to running all the examples in one iteration.</p>
<ul>
  <li>You don't need to implement anything for this part. Simply run the cells below. </li>
  <li>A good way to verify that gradient descent is working correctly is to look at the value of \(J(w,b)\) and check that it is decreasing with each step. </li>
  <li>Assuming you have implemented the gradient and computed the cost correctly and you have an appropriate value for the learning rate alpha, $J(w,b)$ should never increase and should converge to a steady value by the end of the algorithm.  </li>
</ul>

<h4>6.1 Expected Output</h4>

<p>Optimal w, b found by gradient descent </p>


| w                  | b                        |
| -------------------| ------------------------ |
|1.492054            |-3.216610                 |

We will now use our final parameters w, b to find our prediction for single example.

recall:

$$
f_{w,b}(x^{(i)}) = w * x^{i} + b
$$

Let's predict what profit will be for the ares of 35,000 and 70,000 people

- The model takes in population of a city in 10,000s as input. 

- Therefore, 35,000 people can be translated into an input to the model as `input[] = {3.5}`

- Similarly, 70,000 people can be translated into an input to the model as `input[] = {7.5}`










  </div>
  <div class="col-4 sm-width-full mt-3 border-top-thin "/>
  <div class="table pt-2">
    <div class="inline-block mb-0 mr-1">
      <svg height="32" class="header-social-accent" version="1.1" width="32" viewBox="0 0 16 16" aria-hidden="true">
 <circle cx="8" cy="8" r="8"/>
</svg>

    </div>
    <div class="inline-block mb-0 mr-1">
      <svg height="32" class="header-social-accent" version="1.1" width="32" viewBox="0 0 16 16" aria-hidden="true">
 <circle cx="8" cy="8" r="8"/>
</svg>

    </div>
    <div class="inline-block mb-0 mr-1">
      <a href="https://twitter.com/intent/tweet?text=Tuning+GPT-3+on+a+Single+GPU&amp;url=https%3A%2F%2Fdecentdescent.org%2Ftp5.html" title="Share on twitter" class="link-social block">
  <svg height="32" class="header-social-op" version="1.1" width="32" viewBox="0 0 16 16" aria-hidden="true">
    <path d="M8,0C3.6,0,0,3.6,0,8s3.6,8,8,8s8-3.6,8-8S12.4,0,8,0z M12,6c0,0.1,0,0.2,0,0.3c0,2.7-2.1,5.8-5.8,5.8
  	c-1.2,0-2.2-0.3-3.1-0.9c0.2,0,0.3,0,0.5,0c1,0,1.8-0.3,2.5-0.9c-0.9,0-1.7-0.6-1.9-1.4c0.1,0,0.3,0,0.4,0c0.2,0,0.4,0,0.5-0.1
  	c-0.9-0.2-1.6-1-1.6-2v0C3.7,6.9,4,7,4.3,7.1c-0.5-0.4-0.9-1-0.9-1.7c0-0.4,0.1-0.7,0.3-1c1,1.2,2.5,2.1,4.2,2.1
  	c0-0.2-0.1-0.3-0.1-0.5c0-1.1,0.9-2,2.1-2c0.6,0,1.1,0.2,1.5,0.6c0.5-0.1,0.9-0.3,1.3-0.5c-0.2,0.5-0.5,0.9-0.9,1.1
  	c0.4,0,0.8-0.2,1.2-0.3h0C12.7,5.3,12.4,5.7,12,6z"/>
  </svg>
</a>

    </div>
    <div class="inline-block mb-0 mr-1">
      <a onclick="parent.postMessage('submit','*')" href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fdecentdescent.org%2Ftp5.html&amp;t=Tuning+GPT-3+on+a+Single+GPU" title="Share on Hacker News" class="link-social block">
  <svg height="32" class="header-social-op" version="1.1" width="32" viewBox="0 0 496 496" aria-hidden="true">
    <path d="M 248,0 C 111,0 0,111 0,248 0,385 111,496 248,496 385,496 496,385 496,248 496,111 385,0 248,0 Z m -96,120 h 37.30078 c 52.5,98.3 49.19883,101.19961 59.29883,125.59961 12.3,-27 5.79961,-24.39961 60.59961,-125.59961 H 344 L 263.19922,275.09961 V 376 H 231.80078 V 273.30078 Z M 45.087891,221.17773 c 0.03739,0.007 0.07799,0.0215 0.111328,0.0215 H 45 c 0.01711,-0.0286 0.0505,-0.0286 0.08789,-0.0215 z
"/>
  </svg>
</a>

    </div>
    <div class="inline-block mb-0 mr-1">
      <a href="http://reddit.com/submit?url=https%3A%2F%2Fdecentdescent.org%2Ftp5.html&amp;title=Tuning+GPT-3+on+a+Single+GPU" title="Share on Reddit" class="link-social block">
  <svg height="32" class="header-social-op" version="1.1" width="32" viewBox="8 8 496 496" aria-hidden="true">
    <path d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5
    26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"/>
  </svg>
</a>

    </div>
    <div class="inline-block mb-0 mr-1">
      <a href="https://facebook.com/sharer.php?u=https%3A%2F%2Fdecentdescent.org%2Ftp5.html" title="Share on Facebook" class="link-social block">
  <svg height="32" class="header-social-op" version="1.1" width="32" viewBox="8 8 496 496" aria-hidden="true">
    <path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"
/>
  </svg>
</a>

    </div>
  </div>

</article>


    </div>

    <!--
<div class="border-top-thin clearfix mt-2 mt-lg-4">
  <div class="container mx-auto px-2">
    <p class="col-8 sm-width-full left py-2 mb-0">This project is maintained by <a class="text-accent" href="https://github.com/"></a></p>
    <ul class="list-reset right clearfix sm-width-full py-2 mb-2 mb-lg-0">
      <li class="inline-block mr-1">
        <a href="https://twitter.com/share" class="twitter-share-button" data-hashtags="Decent Descent">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
      </li>
      <li class="inline-block">
        <a class="github-button" href="https://github.com//" data-icon="octicon-star" data-count-href="//stargazers" data-count-api="/repos//#stargazers_count" data-count-aria-label="# stargazers on GitHub" aria-label="Star / on GitHub">Star</a>
      </li>
    </ul>
  </div>
</div>
-->
<div class="clearfix mt-2 mt-lg-4">
  <div class="container mx-auto px-2">
  </div>
</div>

<!--
<script>
  $("script[type='math/tex']").replaceWith(function() {
      var tex = $(this).text();
      return katex.renderToString(tex, {displayMode: false});
  });

  $("script[type='math/tex; mode=display']").replaceWith(function() {
      var tex = $(this).html();
      return katex.renderToString(tex.replace(/%.*/g, ''), {displayMode: true});
  });
</script>
-->


  </body>

</html>