
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Univariate Linear Regression</title>
  <script>(function(d) {var config = {kitId: 'all7jvn',scriptTimeout: 1000,async: true},h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)})(document);</script>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="https://lightning.svbtle.com/cargo/favicon-3686f5990e669ad2a1684f0ac250c4d9ddc03e2ef6f3c980f17b7aae786833ef.ico">
  <link rel="icon" sizes="196x196" href="https://lightning.svbtle.com/cargo/apple-touch-icon-8ed2bd858a30400ead0535543ffb8ad2ab3e036a2f0adb797dc641458d00a41a.png">
  <link rel="mask-icon" href="https://lightning.svbtle.com/cargo/default-b7e7b5361ab4c50a9ceb6dc296e0f157e2ec9c2f2c6f30832d991dc361d69512.svg" color="black">
  <!-- <meta name="generator" content="Svbtle.com" /> -->
  <meta name="description" content="C programming| Isack Odero "/>
  <link rel="canonical" href="https://oderoi.github.io/ulr" />
  <meta property="og:url" content="https://oderoi.github.io/ulr" />
  <meta property="twitter:site" content="@svbtle" />
  <meta property="twitter:title" content="Univariate Linear Regression" />
  <meta property="twitter:description" content="Univariate Linear Regression with C programming, ..." />
  <meta property="twitter:creator" content="@oderoi_" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:image" content="https://lightning.svbtle.com/cargo/icons/svbtle_logo-ba4b41e5249a7e3f19288fa586ea973569bfb83452114886be65bc5d8eb13b21.png" />
  <meta property="twitter:domain" content="https://oderoi.githu.io" />
  <meta property="og:title" content="Univariate Linear Regression &bull; Isack Odero" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="Univariate Linear Regression using C programming language, ... | Isack Odero" />
  <meta property="og:image" content="https://lightning.svbtle.com/cargo/icons/svbtle_logo-ba4b41e5249a7e3f19288fa586ea973569bfb83452114886be65bc5d8eb13b21.png" />
  <meta property="og:site_name" content="Isack Odero" />
  <meta property="fb:app_id" content="346346195413177" />
  <link rel="alternate" type="application/rss+xml" href="https://oderoi.github.io/feed" />
  <link rel="stylesheet" href="https://lightning.svbtle.com/cargo/legacy/build.blog-120c367e4cc2cdf2d031c71f795ecea0ef4033f8b24d12d8e147c86e08e2ed2a.css" media="all" data-turbolinks-track="reload" />
  <script src="https://lightning.svbtle.com/cargo/build.blog-41a284c81b4230cd8ab812d35fabef8cc99e927407ed15604d3206997ef79818.js" data-turbolinks-track="reload"></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-VGMRYDBB5R"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('set', 'linker', {
      'accept_incoming': true
    });
    gtag('config', 'G-VGMRYDBB5R');
    gtag('config', 'UA-26652609-2');
  </script>  
  <script src="https://lightning.svbtle.com/cargo/share_buttons-dd547cdb8c37c1c5b949d9a5f034ef854d39634831852762b3d730f59a9e47d4.js" data-turbolinks-track="true"></script>
  <script src="//platform.twitter.com/widgets.js" async></script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
  
  <style>
    /* Make the container responsive */
    pre {
      white-space: pre-wrap; /* Line break preservation */
      word-wrap: break-word; /* Prevent overflow */
      font-size:medium; /* Adjust font size based on screen size */
      padding: 10px;
      background-color: #f4f4f4; /* Light grey background */
      border-radius: 5px;
      overflow: auto;
    }

    /* Responsive font size */
    @media screen and (max-width: 768px) {
      pre {
        font-size: 0.9rem; /* Slightly smaller font for smaller screens */
      }
    }

    @media screen and (max-width: 480px) {
      pre {
        font-size: 0.8rem; /* Smaller font for mobile screens */
      }
    }

    /* Responsive image */
    img {
      max-width: 100%; /* Image takes up full width of its container */
      height: auto; /* Maintain aspect ratio */
      display: block;
      margin: 10px 0; /* Margin around the image */
    }
  </style>

</head>
<body class="overlord blog">
<style scoped>
figure#user_logo a,
figure#user_foot a,
figure.avatar a,
nav#overlord.user_top figure#logo_top a,
figure.kudo.complete div.filling {
  background-image: url('https://lightning.svbtle.com/cargo/blank-3dc89b51de1fd0e237e0320a05be98fb1f11cc04dcf200934ba8a64deec81ffd.png')
}

figure.kudo.activated div.filling,
figure.kudo.complete div.filling {
  background-color: #000000;
}

figure.kudo.activated a,
figure.kudo.complete a {
  border-color: #000000;
}

blockquote,
a blockquote,
div#readnext:hover span.flank_title,
div#foot_more:hover a,
div#foot_userbar a#bottom_tagline span:hover,
article.linked h1.article_title a:hover,
a.continue_button:hover,
article p a:hover,
ul#lightning_drop,
figure#user_foot,
ul#user_links li a:hover,
ul#foot_links li a:hover,
a.buttonize:hover,
button.buttonize:hover,
a.buttonize.outline:hover,
button.buttonize.outline:hover,
nav.pagination span.next a:hover,
nav.pagination span.prev a:hover,
section#readnext:hover p span,
nav#overlord.user_top figure#logo_top {
  border-color: #000000;
}
/*figure#user_logo,*/

figure.avatar,
nav#overlord.user_top figure#logo_top a,
ul#user_links li a:hover,
ul#foot_links li a:hover,
a.buttonize:hover,
button.buttonize:hover,
a.buttonize.outline:hover,
button.buttonize.outline:hover,
nav.pagination span.next a:hover,
nav.pagination span.prev a:hover,
figure#user_logo a,
figure#user_foot a  {
	background-color: #000000;
}

h6.separator_title.read_first,
header#user_top h2 a,
footer#blog_foot h5 a,
article.post h1 a:hover,
div.preview strong,
nav#overlord h2#nav_title.user_top a,
section#readnext:hover h3,
section#readnext:hover p span {
  color: #000000;
}

@keyframes titlePulse
  {
  0% {
    color: #000000;
  }
  50% {
    color: #000000;
  }
  100% {
    color: #000000;
  }
}

@-moz-keyframes titlePulse
  {
  0% {
    color: #000000;
  }
  50% {
    color: #000000;
  }
  100% {
    color: #000000;
  }
}

@-webkit-keyframes titlePulse
  {
  0% {
    color: #000000;
  }
  50% {
    color: #000000;
  }
  100% {
    color: #000000;
  }
}


</style>

<figure id="loading">&nbsp;</figure>
<nav id="overlord" class="user_top">
  <div id="lockup" class="">
    <figure id="logo_top" class=" user_top">
      <a href="/">Svbtle</a>
    </figure>
    <h2 id="nav_title" class="user_top"><a href="https://oderoi.github.io">Isack Odero</a></h2>
  </div>
  <figure id="hamburger">
    <a href="#menu" id="hamburger_button">Menu</a>
  </figure>
  <ul id="dropdown" class="onblog">
    <li><a href="https://x.com/oderoi_" class="xdotcom" target="_blank">@oderoi</a></li>
    <li style="margin: 0; padding: 0;"><hr class="overlord_nav" /></li>
    <li><a href="about_me.html">about me</a></li>
  </ul>
</nav>
<div id="whiteout"></div>

<section id="container" class="blog user_post">
  <article id="angbJyhsMUeJe4t4KyKHG1" class="post  historical">
	<time datetime="2016-05-03" class="article_time">May  3, 2016</time>
  <h1 class="article_title">
    <a href="https://oderoi.github.io/ulr">Univariate Linear Regression</a>
  </h1>
	<h1 id="problem_statement_1">Problem statement <a class="head_anchor" href="#problem_statement_1">#</a></h1>
  <p>Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet.</p>
  <p>
    <ul>
      <li>You would like to expand your business to cities that may give your restaurant higher profits.</li>
      <li>The chain already has restaurants in various cities and you have data for profits and populations from the cities.</li>
      <li>You also have data on cities that are candidates for a new restaurant. </li>
      <ul>
        <li>For these cities, you have the city population.</li>
      </ul>
    </ul>
  </p>
  <p>Can you use the data to help you identify which cities may potentially give your business higher profits?</p>
  <p>Note:</p>
  <ul>
    <li>'X' is the population of a city</li>
    <li>'y' is the profit of a restaurant in that city. A negative value for profit indicates a loss. </li>
    <ul>
      <li>Both 'X' and 'y' are arrays.</li>
    </ul>
  </ul>

  <table>
    <tr>
      <th>Population of a city (<b>x</b> 10,000) as \(x\) </th>
      <th>Profit of a restaurent (<b>x</b> $10,000) as \( f_{w,b}(x^{(i)}) \)or \(x\) </th>
      
  </tr>
    <tr>
      <td>6.1101</td>
      <td>17.592</td>
    </tr>
    <tr>
      <td>5.5277</td>
      <td>9.1302</td>
    </tr>
    <tr>
      <td>8.5186</td>
      <td>13.662</td>
    </tr>
    <tr>
      <td>7.0032</td>
      <td>11.854</td>
    </tr>
    <tr>
      <td>5.8598</td>
      <td>6.8233</td>
    </tr>
  </table>
  <p>Number of training example (size (1000 sqft) as x) \(m\)</p>
  <p>In this case \(m = 5\)</p>

  <h1 id="model_function_1">Model Function <a class="head_anchor" href="#model_function_1">#</a></h1>
  <p>The model function for linear regression (which is a function that maps from \(x\) to \(y\) is represented as</p>
  <p>$$f_{w,b}(x^{(i)}) = w*x^{(i)} + b \tag{1}$$</p>


  <blockquote>

    <pre>
      <code>
        float *compute_model_output(float x[], float w, float b, int m){

          /*
          Computes the prediction of a linear model
          Args:
          X[m] (ndarray (m,1)): Data, m examples 
          w,b (scalar)     : model parameters 
          m (scalar)       : number of examples, X
          Returns
          Y[m] (ndarray (m,1)): target values
          */
      
          float *f_x = (float *)malloc(m * sizeof(float));
      
          for(int i = 0; i < m; i++){
            f_x[i] = x[i] * w + b;
          }
          return f_x;
        }
      </code>
    </pre>
  </blockquote>


<h1 id="compute_cost_1">Compute Cost <a class="head_anchor" href="#compute_cost_1">#</a></h1>
<p>Cost is the measure of how well our model will predict the target output well, in this case target output is Profit of a restaurent.</p>
<p>Gradient descent involve repeated steps to adjust the values of <b>w</b> and <b>b</b> to get smaller and smaller <b>Cost</b>, \(J(w,b)\).</p>
<p>The equation for Cost with one variable</p> 
$$J(w,b) = \frac{1}{2m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \tag{2}$$ 

<p>where</p> 
  $$f_{w,b}(x^{(i)}) = w*x^{(i)} + b \tag{1}$$
  
<ul>
  <li>\(f_{w,b}(x^{(i)}) \)is our prediction for example $i$ using parameters \(w,b\).</li>
  <li>\((f_{w,b}(x^{(i)}) -y^{(i)})^2\) is the squared difference between the target value and the prediction. </li>
  <li>These differences are summed over all the $m$ examples and divided by <b>2*m</b> to produce the cost, \(J(w,b)\).</li>
</ul>
   
<p>Note,</p> 
<ul>
  <li>
    Summation ranges are typically from 1 to m, while code will be from 0 to m-1.
  </li>
</ul>

<blockquote>
  <pre>
    <code>
      float compute_cost(float x[], float y[], float w, float b, int m){

        /*
        Computes the cost function for linear regression.
    
        Args:
        X (ndarray (m,1)): Data, m examples 
        Y (ndarray (m,1)): target values
        w,b (scalar)     : model parameters  
        m (scalar)       : number of examples, X
    
        Returns
          total_cost (float): The cost of using w,b as the parameters for linear regression
                to fit the data points in X and Y
        */
    
        float J_wb = 0;
        float f_x;
    
        for (int i = 0; i < m; i++)
        {
          f_x = x[i] * w + b; 
          J_wb += pow((f_x - y[i]), 2);
        }
        J_wb /= (2 * m);
    
        return J_wb;
      }
    </code>
  </pre>
</blockquote>



<h2 id="compute_cost_1">Cost versus iterations of gradient descent <a class="head_anchor" href="#compute_cost_1">#</a></h2>

<p>A plot of cost versus iterations is a useful measure of progress in gradient descent. Cost should always decrease in successful runs. The change in cost is so rapid initially, it is useful to plot the initial decent on a different scale than the final descent. In the plots below, note the scale of cost on the axes and the iteration step.</p>

<img src="./images/cost.png" class="limit-height">


<h2 id="compute_cost_1">Plot of cost J(w,b) vs w,b with path of gradient descent <a class="head_anchor" href="#compute_cost_1">#</a></h2>

<p>Plot shows the $cost(w,b)$ over a range of $w$ and $b$. Cost levels are represented by the rings. Overlayed, using red arrows, is the path of gradient descent. Here are some things to note:</p>
<ul>
  <li>The path makes steady (monotonic) progress toward its goal.</li>
  <li>initial steps are much larger than the steps near the goal.</li>
</ul>

<img src="./images/counter_cost.png" class="limit-height">
<p>I kept trying to find time for programming language research. But I also kept getting distracted by new startup ideas (generally pretty bad), and new people to work on them with (generally pretty good). I’d started out at Harvard and transferred to MIT, trying to constantly surround myself by people who I could learn from and build something useful with.</p>

<p>Junior year, I decided that it didn’t make sense to try to do a startup while still in school. Instead, I was going to meet with people doing startups, and over time pattern match what works and what doesn’t. In the meanwhile, I finally started my programming language research, securing research funds from a professor and recruiting some of my friends for a static buffer overrun detection project.</p>

<p>A few weeks later, I was contacted by an unlaunched startup in Palo Alto. Normally I would have discarded the email, but I’d decided to start meeting startups. The team and I instantly clicked, and I knew that these were exactly the kind of people I’d been looking for all along. So I left school, never to actually get our buffer overrun detector working.</p>
<h1 id="stripe_1">Stripe <a class="head_anchor" href="#stripe_1">#</a></h1>
<p>That company is <a href="https://www.quora.com/How-did-Stripe-come-up-with-its-name">now</a> <a href="https://stripe.com/">Stripe</a>. I helped scale it from 4 to 250 people, and in the year since I left it’s continued scaling without any of my help to over 450.</p>

<p>When I considered <a href="/leaving-stripe">leaving</a>, it was primarily because I felt like the company was in a great place, and it would continue to do great things with or without me. I cared most about working with great people to make something amazing happen — but developer infrastructure wasn’t the problem that I wanted to work on for the rest of my life.</p>

<p>However, there was one problem that I could imagine happily working on for the rest of my life: moving humanity to safe human-level AI. It’s hard to imagine anything more amazing and positively impactful than successfully creating AI, so long as it’s done in a good way.</p>
<h1 id="leaving-stripe_1">Leaving Stripe <a class="head_anchor" href="#leaving-stripe_1">#</a></h1>
<p>Before I finalized my decision to leave, <a href="https://en.wikipedia.org/wiki/Patrick_Collison">Patrick</a> asked me to go talk to <a href="https://en.wikipedia.org/wiki/Sam_Altman">Sam Altman</a>. He said Sam had a good outsider’s perspective, had seen lots of people in similar circumstances, and would probably have a good recommendation on what I should do.</p>

<p>Within five minutes of talking to Sam, he told me I was definitely ready to leave. He said to let him know if he could be helpful in figuring out my next thing.</p>

<p>I replied that AI was top of my list (and it was definitely my life goal). However, I wasn’t yet sure whether it was the right time, or what the best way for me to contribute would be.</p>

<p>He said, “We’ve been thinking about spinning up an AI lab through YC. We should keep in touch.”</p>
<h1 id="initial-exploration_1">Initial exploration <a class="head_anchor" href="#initial-exploration_1">#</a></h1>
<p>I left Stripe about a week or two later, and started digging into AI to try to better understand what was happening in the field. Even just from watching posts that made it onto Hacker News (such as <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">char-rnn</a>), it was clear that there was mounting excitement and activity around AI generally and deep learning particularly. But I approached the field with healthy skepticism: I wanted to be sure things were really working before diving in.</p>

<p>My first goal was to figure out what deep learning actually was. It turned out this was surprisingly hard. For example, <a href="http://deeplearning.net/">deeplearning.net</a> just says “Deep Learning is a new area of Machine Learning research, which has been introduced with the objective of moving Machine Learning closer to one of its original goals: Artificial Intelligence” — which sounds exciting but isn’t very descriptive <strong>[1]</strong>.</p>

<p>Fortunately, I had some friends working in AI, <a href="https://www.linkedin.com/in/dario-amodei-3934934">Dario Amodei</a> and <a href="https://colah.github.io/">Chris Olah</a>. I asked them for some pointers, and they gave me some good starter resources. The most useful of these was <a href="http://neuralnetworksanddeeplearning.com/">Michael Nielsen’s book</a>, and after reading it I practiced my newfound skills on <a href="https://www.kaggle.com">Kaggle</a>. (I was even number 1 for a while on my <a href="https://www.kaggle.com/c/denoising-dirty-documents">first contest</a>!)</p>
<h1 id="kindling_1">Kindling <a class="head_anchor" href="#kindling_1">#</a></h1>
<p>Along the way, I kept meeting super smart people in AI, and reconnected with some of my smartest friends from college, such as <a href="https://paulfchristiano.com/">Paul Christiano</a> and <a href="http://cs.stanford.edu/%7Ejsteinhardt/">Jacob Steinhardt</a>, who were now working in the field. This was a strong signal.</p>

<p>The more I dug, the more I became convinced that AI was poised for impact. Deep learning capabilities are incredibly impressive: for example, we can now classify objects in images with <a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/">extreme accuracy</a> (despite this 2014 <a href="http://xkcd.com/1425/">XKCD</a>), <a href="https://www.technologyreview.com/s/544651/baidus-deep-learning-system-rivals-people-at-speech-recognition/">speech recognition</a> has gotten very good, and we can generate surprisingly <a href="https://github.com/Newmu/dcgan_code#bedrooms-after-5-epochs">realistic images</a>. That being said, these technologies are new enough that they haven’t yet changed how anyone lives: their impact today is limited to powering certain <a href="https://www.quora.com/How-is-Machine-Learning-applied-to-Google-Photos">product features</a>.</p>

<p>I remember saying this to one of my friends who had built Facebook News Feed back in the day. His reply was skeptical. “Simple algorithms, lots of data.” Everyone tries to peddle cool new AI algorithms, but in reality, if you just scale up a logistic regression it works really well. I then pulled out the <a href="http://www.forbes.com/sites/amitchowdhry/2015/07/30/google-translates-word-lens-feature-now-supports-27-languages">Google Translate app</a> from my pocket, put it in airplane mode, and demonstrated how it translates the text under the camera directly on the image. He was suitably impressed, and admitted simple algorithms wouldn’t help there. (It’s mostly but not 100% <a href="http://googleresearch.blogspot.com/2015/07/how-google-translate-squeezes-deep.html">deep learning</a>, but that’s not the point — the point is it <strong>works</strong>.)</p>
<h1 id="initial-spark_1">Initial spark <a class="head_anchor" href="#initial-spark_1">#</a></h1>
<p>In June, Sam pinged me asking if I’d figured out yet what to do next. I told him my current plan was to start an AI company within the next year. We jumped on a call, where he mentioned that they were moving forward with the YC AI project. I asked Sam what the purpose of the lab was.</p>

<p>“To build safe human-level AI”, he said.</p>

<p>At that moment I knew he was the right partner to build my next company with. Very few people today would have the audacity to explicitly try building human-level AI. I realized that sometimes an effort needs only someone bold enough to pronounce a goal, and then the right people will join them.</p>
<h1 id="the-dinner_1">The dinner <a class="head_anchor" href="#the-dinner_1">#</a></h1>
<p>About a month later, Sam set up a dinner in Menlo Park. On the list were Dario, Chris, Paul, <a href="http://www.cs.toronto.edu/%7Eilya/">Ilya Sutskever</a>, <a href="https://en.wikipedia.org/wiki/Elon_Musk">Elon Musk</a>, Sam, and a few others.</p>

<p>We talked about the state of the field, how far off human-level AI seemed to be, what you might need to get there, and the like. The conversation centered around what kind of organization could best work to ensure that AI was beneficial.</p>

<p>It was clear that such an organization needed to be a non-profit, without any competing incentives to dilute its mission. It also needed to be at the cutting edge of research (per the <a href="https://en.wikipedia.org/wiki/Alan_Kay">Alan Kay</a> quote, “the best way to predict the future is to invent it”). And to do that, it would need the best AI researchers in the world.</p>

<p>So the question became: would it be possible to create from scratch a lab with the best AI researchers? Our conclusion: not obviously impossible.</p>

<p>This was my first time meeting Elon and Ilya, and I strongly remember my impressions of both. I was struck by how inquisitive Elon was, and how much he sought others opinions and really listened to them. Ilya on the other hand was a source of grounding: he was a clear technical expert with a breadth of knowledge and vision, and could always dive into the specifics of the limitations and capabilities of current systems.</p>

<p>After the dinner concluded, Sam gave me a ride back to the city. We both agreed that it seemed worth starting something here. I knew it would only happen if someone was willing to go full-time on figuring out exactly what that would be and who would be a part of it. I volunteered myself as tribute.</p>

<p>And so the next day, I had something impactful to build once again.</p>

<p><strong>Footnotes:</strong></p>

<p><strong>[1]</strong> I asked Ilya to suggest a good definition:</p>
<blockquote><p>The goal of supervised deep learning is to solve almost any problem of the form “map <code class="prettyprint">X</code> to <code class="prettyprint">Y</code>”. <code class="prettyprint">X</code> can include images, speech, or text, and <code class="prettyprint">Y</code> can include categories or even sentences. Mapping images to categories, speech to text, text to categories, go boards to good moves, and the like, is extremely useful, and cannot be done as well with other methods.</p>

<p>An attractive feature of deep learning is that it is largely domain independent: many of the insights learned in one domain apply in other domains.</p>

<p>Under the hood, the model builds up layers of abstraction. These abstractions get the job done, but it’s really hard to understand how exactly they do it. The model learns by gradually changing the synaptic strengths of the neural network using the incredibly simple yet mysteriously effective <a href="http://neuralnetworksanddeeplearning.com/chap2.html">backpropagation algorithm</a>. As a result, we can build massively sophisticated systems using very few lines of code (since we only code the model and the learning algorithm, but not the end result).</p>
</blockquote>
  <figure class="postend kudo able clearfix" id="kudo_angbJyhsMUeJe4t4KyKHG1">
    <a href="#kudo">
      <div class="filling">&nbsp;</div>
    </a>
    <div class="num">2,076</div>
    <div class="txt">Kudos</div>
  </figure>
  <figure class="side kudo able clearfix" id="kudo_side_angbJyhsMUeJe4t4KyKHG1">
    <a href="#kudo">
      <div class="filling">&nbsp;</div>
    </a>
    <div class="num">2,076</div>
    <div class="txt">Kudos</div>
  </figure>
</article>

  <div id="share_links" data-no-turbolink>
    <a href="https://twitter.com/share" class="twitter-share-button" data-via="gdb" data-related="svbtle" data-no-turbolink>Tweet</a>
    <div style="margin-top: 4px; margin-bottom: 8px; margin-left: 0px; display: block;" class="fb-share-button" data-href="https://blog.gregbrockman.com/my-path-to-openai" data-layout="button_count" data-no-turbolink></div>
  <div>
</section>
<section id="readnext">
  <a href="https://blog.gregbrockman.com/define-cto-openai">
    <h4 class="readnext_header">Now read this</h4>
    <h3 class="readnext_title">#define CTO OpenAI</h3>
    <p class="readnext_content">It’s been two years since I wrote #define CTO, in which I documented my quest for a role where I could have scalable impact by writing code. I’ve finally found that role, though not by seeking it — instead, I sought out a problem more... <span class="continue_btn">Continue&nbsp;&rarr;</span></p>
  </a>
</section>
<footer id="blog_foot" class="cf">
  <ul id="foot_links">
    <li><a href="https://x.com/gdb">@gdb</a></li>
    <li><a href="https://gregbrockman.com" >gregbrockman.com</a></li>
  </ul>
  <figure id="user_foot"><a href="/">Svbtle</a></figure>
  <h5><a href="https://blog.gregbrockman.com">Greg Brockman</a></h5>
</footer>
<footer id="foot">
  <figure id="logo_foot"><a href="https://svbtle.com">Svbtle</a></figure>
  <a href="https://svbtle.com/terms" style="color: #ccc; margin-left: 25px;">Terms</a> <span style="color: #ccc;">•</span> <a href="https://svbtle.com/privacy" style="color: #ccc;">Privacy</a>
  <span style="color: #ccc;">•</span> <a href="https://svbtle.com/promise" style="color: #ccc; margin-right: 15px;">Promise</a>
  <br/><br/>
</footer>

<div id="lights">&nbsp;</div>
<div id="app-data" data-name="svbtle" data-version="8.5-legible" data-magicNum="2572031820.15"></div><div id="px-data" data-ax="posts" data-sx="show"></div><div id="user-data" data-here="false" data-state="logged-out"></div><div id="blog-data" data-title="Greg Brockman" data-blogname="gdb" data-extid="8SMTiky8WK9x16AjSma1Vx" data-color="000000" data-color-rgb="0,0,0" data-color-rgba="(0,0,0,0.5)" data-blog-tracker="UA-26652609-2"></div></body>
</html>